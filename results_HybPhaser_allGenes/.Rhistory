for(i in 1:nloci){
seq_per_locus[i] <- length(which(!(is.na(loci[,i]))))
}
names(seq_per_locus) <- colnames(loci)
seq_per_locus_prop <- seq_per_locus/nsamples
# per sample
seq_per_sample <- vector()
for(i in 1:length(colnames(tab_snps))){
seq_per_sample[i] <- length(which(!(is.na(tab_snps[,i]))))
}
names(seq_per_sample) <- colnames(tab_snps)
seq_per_sample_prop <- seq_per_sample/nloci
# proportion of target sequence length
if(targets_file_format == "AA"){
targets_length_all <- lengths(read.FASTA(fasta_file_with_targets, type = "AA"))*3
} else if(targets_file_format == "DNA"){
targets_length_all <- lengths(read.FASTA(fasta_file_with_targets))
} else {
print("Warning! Target file type not set properly. Should be 'DNA' or 'AA'!")
}
gene_names <- unique(gsub(".*-","",gsub(" .*","",names(targets_length_all))))
max_target_length <- vector()
for(i in 1:length(gene_names)){
max_target_length[i] <- max(targets_length_all[grep(paste("\\b",gene_names[i],"\\b",sep=""),names(targets_length_all))])
}
names(max_target_length) <- gene_names
comb_target_length <- sum(max_target_length)
comb_seq_length_samples <- colSums(tab_length, na.rm = T)
prop_target_length_per_sample <- comb_seq_length_samples/comb_target_length
mean_seq_length_loci <- rowMeans(tab_length, na.rm = T)
names(mean_seq_length_loci) <- gene_names
prop_target_length_per_locus <- mean_seq_length_loci/max_target_length
# application of thresholds
outsamples_missing_loci <- seq_per_sample_prop[which(seq_per_sample_prop < remove_samples_with_less_than_this_propotion_of_loci_recovered)]
outsamples_missing_target <- prop_target_length_per_sample[which(prop_target_length_per_sample < remove_samples_with_less_than_this_propotion_of_target_sequence_length_recovered)]
outsamples_missing <- unique(names(c(outsamples_missing_loci,outsamples_missing_target)))
outloci_missing_samples <- seq_per_locus_prop[which(seq_per_locus_prop < remove_loci_with_less_than_this_propotion_of_samples_recovered)]
outloci_missing_target <- prop_target_length_per_locus[which(prop_target_length_per_locus < remove_loci_with_less_than_this_propotion_of_target_sequence_length_recovered)]
outloci_missing <- unique(names(c(outloci_missing_samples,outloci_missing_target)))
# removing bad loci and samples from the table
tab_snps_cl1 <- tab_snps
if(length(outsamples_missing) != 0){
tab_snps_cl1 <- tab_snps_cl1[,-which(colnames(tab_snps) %in% outsamples_missing)]
}
if(length(outloci_missing) != 0){
tab_snps_cl1 <- tab_snps_cl1[-which(rownames(tab_snps) %in% outloci_missing),]
}
loci_cl1 <- t(tab_snps_cl1)
loci_cl1_colmeans <- colMeans(as.matrix(loci_cl1), na.rm = T)
nloci_cl1 <- length(colnames(loci_cl1))
nsamples_cl1 <- length(colnames(tab_snps_cl1))
loci_cl1_colmeans_mean <- round(mean(loci_cl1_colmeans),4)
loci_cl1_colmeans_median <- round(median(loci_cl1_colmeans),4)
# applying chosen threshold
if (length(remove_loci_for_all_samples_with_more_than_this_mean_proportion_of_SNPs) != 1 || remove_loci_for_all_samples_with_more_than_this_mean_proportion_of_SNPs == "none"){
outloci_para_all <- vector()
threshold_value <- 1
} else if (remove_loci_for_all_samples_with_more_than_this_mean_proportion_of_SNPs == "outliers"){
threshold_value <- 1.5*IQR(loci_cl1_colmeans, na.rm = TRUE )+quantile(loci_cl1_colmeans, na.rm = TRUE )[4]
outloci_para_all_values <- loci_cl1_colmeans[which(loci_cl1_colmeans > threshold_value)]
outloci_para_all <- names(outloci_para_all_values)
} else if (remove_loci_for_all_samples_with_more_than_this_mean_proportion_of_SNPs == "file"){
if(file.exists(file_with_putative_paralogs_to_remove_for_all_samples) == FALSE){
print("File with list of paralogs to remove for all samples does not exist.")
} else {
outloci_para_all <- readLines(file_with_putative_paralogs_to_remove_for_all_samples)
outloci_para_all_values <-loci_cl1_colmeans[which(names(loci_cl1_colmeans) %in% outloci_para_all)]
}
} else {
threshold_value <- remove_loci_for_all_samples_with_more_than_this_mean_proportion_of_SNPs
outloci_para_all_values <- loci_cl1_colmeans[which(loci_cl1_colmeans > threshold_value)]
outloci_para_all <- names(outloci_para_all_values)
}
loci_cl1_colmeans
write.csv(loci_cl1_colmeans, file = "loci_cl1_colmeans.csv")
config_file <- "./config_superstrict.txt"
# load config
#if (!(exists("config_file"))) {config_file <- "./config_superstrict.txt"}
source(config_file)
# generate folders
if(name_for_dataset_optimization_subset != ""){
folder_subset_add <- paste("_",name_for_dataset_optimization_subset, sep="")
}else {
folder_subset_add <- ""
}
output_Robjects <- file.path(path_to_output_folder,"00_R_objects", name_for_dataset_optimization_subset)
output_assess <- file.path(path_to_output_folder,paste("02_assessment", folder_subset_add, sep=""))
# check if SNPs count for subset has been done, if not use SNPs count of first run subset with name "")
if(file.exists(file=file.path(output_Robjects,"Table_SNPs.Rds"))){
tab_snps <- readRDS(file=file.path(output_Robjects,"Table_SNPs.Rds"))
tab_length <- readRDS(file=file.path(output_Robjects,"Table_consensus_length.Rds"))
} else {
tab_snps <- readRDS(file=file.path(path_to_output_folder,"00_R_objects/Table_SNPs.Rds"))
tab_length <- readRDS(file=file.path(path_to_output_folder,"00_R_objects/Table_consensus_length.Rds"))
}
tab_snps <- as.matrix(tab_snps)
loci <- t(tab_snps)
nloci <- length(colnames(loci))
nsamples <- length(rownames(loci))
failed_loci <- which(colSums(is.na(loci))==nrow(loci))
failed_samples <- which(colSums(is.na(tab_snps))==nrow(tab_snps))
####KasperH added: save failed_loci and failed_samples; these are again needed in script 1c.
saveRDS(failed_loci, file = file.path(output_Robjects, "failed_loci.Rds"), version = 2)
saveRDS(failed_samples, file = file.path(output_Robjects, "failed_samples.Rds"), version = 2)
# per locus
seq_per_locus <- vector()
for(i in 1:nloci){
seq_per_locus[i] <- length(which(!(is.na(loci[,i]))))
}
names(seq_per_locus) <- colnames(loci)
seq_per_locus_prop <- seq_per_locus/nsamples
# per sample
seq_per_sample <- vector()
for(i in 1:length(colnames(tab_snps))){
seq_per_sample[i] <- length(which(!(is.na(tab_snps[,i]))))
}
names(seq_per_sample) <- colnames(tab_snps)
seq_per_sample_prop <- seq_per_sample/nloci
# proportion of target sequence length
if(targets_file_format == "AA"){
targets_length_all <- lengths(read.FASTA(fasta_file_with_targets, type = "AA"))*3
} else if(targets_file_format == "DNA"){
targets_length_all <- lengths(read.FASTA(fasta_file_with_targets))
} else {
print("Warning! Target file type not set properly. Should be 'DNA' or 'AA'!")
}
gene_names <- unique(gsub(".*-","",gsub(" .*","",names(targets_length_all))))
max_target_length <- vector()
for(i in 1:length(gene_names)){
max_target_length[i] <- max(targets_length_all[grep(paste("\\b",gene_names[i],"\\b",sep=""),names(targets_length_all))])
}
names(max_target_length) <- gene_names
comb_target_length <- sum(max_target_length)
comb_seq_length_samples <- colSums(tab_length, na.rm = T)
prop_target_length_per_sample <- comb_seq_length_samples/comb_target_length
mean_seq_length_loci <- rowMeans(tab_length, na.rm = T)
names(mean_seq_length_loci) <- gene_names
prop_target_length_per_locus <- mean_seq_length_loci/max_target_length
# application of thresholds
outsamples_missing_loci <- seq_per_sample_prop[which(seq_per_sample_prop < remove_samples_with_less_than_this_propotion_of_loci_recovered)]
outsamples_missing_target <- prop_target_length_per_sample[which(prop_target_length_per_sample < remove_samples_with_less_than_this_propotion_of_target_sequence_length_recovered)]
outsamples_missing <- unique(names(c(outsamples_missing_loci,outsamples_missing_target)))
outloci_missing_samples <- seq_per_locus_prop[which(seq_per_locus_prop < remove_loci_with_less_than_this_propotion_of_samples_recovered)]
outloci_missing_target <- prop_target_length_per_locus[which(prop_target_length_per_locus < remove_loci_with_less_than_this_propotion_of_target_sequence_length_recovered)]
outloci_missing <- unique(names(c(outloci_missing_samples,outloci_missing_target)))
# removing bad loci and samples from the table
tab_snps_cl1 <- tab_snps
if(length(outsamples_missing) != 0){
tab_snps_cl1 <- tab_snps_cl1[,-which(colnames(tab_snps) %in% outsamples_missing)]
}
if(length(outloci_missing) != 0){
tab_snps_cl1 <- tab_snps_cl1[-which(rownames(tab_snps) %in% outloci_missing),]
}
loci_cl1 <- t(tab_snps_cl1)
loci_cl1_colmeans <- colMeans(as.matrix(loci_cl1), na.rm = T)
nloci_cl1 <- length(colnames(loci_cl1))
nsamples_cl1 <- length(colnames(tab_snps_cl1))
loci_cl1_colmeans_mean <- round(mean(loci_cl1_colmeans),4)
loci_cl1_colmeans_median <- round(median(loci_cl1_colmeans),4)
# applying chosen threshold
if (length(remove_loci_for_all_samples_with_more_than_this_mean_proportion_of_SNPs) != 1 || remove_loci_for_all_samples_with_more_than_this_mean_proportion_of_SNPs == "none"){
outloci_para_all <- vector()
threshold_value <- 1
} else if (remove_loci_for_all_samples_with_more_than_this_mean_proportion_of_SNPs == "outliers"){
threshold_value <- 1.5*IQR(loci_cl1_colmeans, na.rm = TRUE )+quantile(loci_cl1_colmeans, na.rm = TRUE )[4]
outloci_para_all_values <- loci_cl1_colmeans[which(loci_cl1_colmeans > threshold_value)]
outloci_para_all <- names(outloci_para_all_values)
} else if (remove_loci_for_all_samples_with_more_than_this_mean_proportion_of_SNPs == "file"){
if(file.exists(file_with_putative_paralogs_to_remove_for_all_samples) == FALSE){
print("File with list of paralogs to remove for all samples does not exist.")
} else {
outloci_para_all <- readLines(file_with_putative_paralogs_to_remove_for_all_samples)
outloci_para_all_values <-loci_cl1_colmeans[which(names(loci_cl1_colmeans) %in% outloci_para_all)]
}
} else {
threshold_value <- remove_loci_for_all_samples_with_more_than_this_mean_proportion_of_SNPs
outloci_para_all_values <- loci_cl1_colmeans[which(loci_cl1_colmeans > threshold_value)]
outloci_para_all <- names(outloci_para_all_values)
}
write.csv(loci_cl1_colmeans, file = "loci_cl1_colmeans.csv")
config_file <- "./config_strict.txt"
# load config
#if (!(exists("config_file"))) {config_file <- "./config_strict.txt"}
source(config_file)
# load packages
library(ape)
library(ggplot2)
# generate folders
if(name_for_dataset_optimization_subset != ""){
folder_subset_add <- paste("_",name_for_dataset_optimization_subset, sep="")
}else {
folder_subset_add <- ""
}
output_Robjects <- file.path(path_to_output_folder,"00_R_objects", name_for_dataset_optimization_subset)
output_assess <- file.path(path_to_output_folder,paste("02_assessment", folder_subset_add, sep=""))
# check if SNPs count for subset has been done, if not use SNPs count of first run subset with name "")
if(file.exists(file=file.path(output_Robjects,"Table_SNPs.Rds"))){
tab_snps <- readRDS(file=file.path(output_Robjects,"Table_SNPs.Rds"))
tab_length <- readRDS(file=file.path(output_Robjects,"Table_consensus_length.Rds"))
} else {
tab_snps <- readRDS(file=file.path(path_to_output_folder,"00_R_objects/Table_SNPs.Rds"))
tab_length <- readRDS(file=file.path(path_to_output_folder,"00_R_objects/Table_consensus_length.Rds"))
}
tab_snps <- as.matrix(tab_snps)
loci <- t(tab_snps)
#colnames(tab_snps)[length(colnames(tab_snps))]<-"Sample8009952"
##########################################################
### Dataset optimization step 1: Reducing missing data ###
##########################################################
nloci <- length(colnames(loci))
nsamples <- length(rownames(loci))
failed_loci <- which(colSums(is.na(loci))==nrow(loci))
failed_samples <- which(colSums(is.na(tab_snps))==nrow(tab_snps))
####KasperH added: save failed_loci and failed_samples; these are again needed in script 1c.
saveRDS(failed_loci, file = file.path(output_Robjects, "failed_loci.Rds"), version = 2)
saveRDS(failed_samples, file = file.path(output_Robjects, "failed_samples.Rds"), version = 2)
# per locus
seq_per_locus <- vector()
for(i in 1:nloci){
seq_per_locus[i] <- length(which(!(is.na(loci[,i]))))
}
names(seq_per_locus) <- colnames(loci)
seq_per_locus_prop <- seq_per_locus/nsamples
# per sample
seq_per_sample <- vector()
for(i in 1:length(colnames(tab_snps))){
seq_per_sample[i] <- length(which(!(is.na(tab_snps[,i]))))
}
names(seq_per_sample) <- colnames(tab_snps)
seq_per_sample_prop <- seq_per_sample/nloci
# proportion of target sequence length
if(targets_file_format == "AA"){
targets_length_all <- lengths(read.FASTA(fasta_file_with_targets, type = "AA"))*3
} else if(targets_file_format == "DNA"){
targets_length_all <- lengths(read.FASTA(fasta_file_with_targets))
} else {
print("Warning! Target file type not set properly. Should be 'DNA' or 'AA'!")
}
gene_names <- unique(gsub(".*-","",gsub(" .*","",names(targets_length_all))))
max_target_length <- vector()
for(i in 1:length(gene_names)){
max_target_length[i] <- max(targets_length_all[grep(paste("\\b",gene_names[i],"\\b",sep=""),names(targets_length_all))])
}
names(max_target_length) <- gene_names
comb_target_length <- sum(max_target_length)
comb_seq_length_samples <- colSums(tab_length, na.rm = T)
prop_target_length_per_sample <- comb_seq_length_samples/comb_target_length
mean_seq_length_loci <- rowMeans(tab_length, na.rm = T)
names(mean_seq_length_loci) <- gene_names
prop_target_length_per_locus <- mean_seq_length_loci/max_target_length
# application of thresholds
outsamples_missing_loci <- seq_per_sample_prop[which(seq_per_sample_prop < remove_samples_with_less_than_this_propotion_of_loci_recovered)]
outsamples_missing_target <- prop_target_length_per_sample[which(prop_target_length_per_sample < remove_samples_with_less_than_this_propotion_of_target_sequence_length_recovered)]
outsamples_missing <- unique(names(c(outsamples_missing_loci,outsamples_missing_target)))
outloci_missing_samples <- seq_per_locus_prop[which(seq_per_locus_prop < remove_loci_with_less_than_this_propotion_of_samples_recovered)]
outloci_missing_target <- prop_target_length_per_locus[which(prop_target_length_per_locus < remove_loci_with_less_than_this_propotion_of_target_sequence_length_recovered)]
outloci_missing <- unique(names(c(outloci_missing_samples,outloci_missing_target)))
# removing bad loci and samples from the table
tab_snps_cl1 <- tab_snps
if(length(outsamples_missing) != 0){
tab_snps_cl1 <- tab_snps_cl1[,-which(colnames(tab_snps) %in% outsamples_missing)]
}
if(length(outloci_missing) != 0){
tab_snps_cl1 <- tab_snps_cl1[-which(rownames(tab_snps) %in% outloci_missing),]
}
loci_cl1 <- t(tab_snps_cl1)
loci_cl1_colmeans <- colMeans(as.matrix(loci_cl1), na.rm = T)
nloci_cl1 <- length(colnames(loci_cl1))
nsamples_cl1 <- length(colnames(tab_snps_cl1))
loci_cl1_colmeans_mean <- round(mean(loci_cl1_colmeans),4)
loci_cl1_colmeans_median <- round(median(loci_cl1_colmeans),4)
# applying chosen threshold
if (length(remove_loci_for_all_samples_with_more_than_this_mean_proportion_of_SNPs) != 1 || remove_loci_for_all_samples_with_more_than_this_mean_proportion_of_SNPs == "none"){
outloci_para_all <- vector()
threshold_value <- 1
} else if (remove_loci_for_all_samples_with_more_than_this_mean_proportion_of_SNPs == "outliers"){
threshold_value <- 1.5*IQR(loci_cl1_colmeans, na.rm = TRUE )+quantile(loci_cl1_colmeans, na.rm = TRUE )[4]
outloci_para_all_values <- loci_cl1_colmeans[which(loci_cl1_colmeans > threshold_value)]
outloci_para_all <- names(outloci_para_all_values)
} else if (remove_loci_for_all_samples_with_more_than_this_mean_proportion_of_SNPs == "file"){
if(file.exists(file_with_putative_paralogs_to_remove_for_all_samples) == FALSE){
print("File with list of paralogs to remove for all samples does not exist.")
} else {
outloci_para_all <- readLines(file_with_putative_paralogs_to_remove_for_all_samples)
outloci_para_all_values <-loci_cl1_colmeans[which(names(loci_cl1_colmeans) %in% outloci_para_all)]
}
} else {
threshold_value <- remove_loci_for_all_samples_with_more_than_this_mean_proportion_of_SNPs
outloci_para_all_values <- loci_cl1_colmeans[which(loci_cl1_colmeans > threshold_value)]
outloci_para_all <- names(outloci_para_all_values)
}
write.csv(loci_cl1_colmeans, file = "loci_cl1_colmeans.csv")
config_file <- "./config_superstrict_by_tribe.txt"
# load config
#if (!(exists("config_file"))) {config_file <- "./config.txt"}
source(config_file)
# load packages
library(ape)
library(ggplot2)
# generate folders
if(name_for_dataset_optimization_subset != ""){
folder_subset_add <- paste("_",name_for_dataset_optimization_subset, sep="")
}else {
folder_subset_add <- ""
}
output_Robjects <- file.path(path_to_output_folder,"00_R_objects", name_for_dataset_optimization_subset)
output_assess <- file.path(path_to_output_folder,paste("02_assessment", folder_subset_add, sep=""))
# check if SNPs count for subset has been done, if not use SNPs count of first run subset with name "")
if(file.exists(file=file.path(output_Robjects,"Table_SNPs.Rds"))){
tab_snps <- readRDS(file=file.path(output_Robjects,"Table_SNPs.Rds"))
tab_length <- readRDS(file=file.path(output_Robjects,"Table_consensus_length.Rds"))
} else {
tab_snps <- readRDS(file=file.path(path_to_output_folder,"00_R_objects/Table_SNPs.Rds"))
tab_length <- readRDS(file=file.path(path_to_output_folder,"00_R_objects/Table_consensus_length.Rds"))
}
tab_snps <- as.matrix(tab_snps)
loci <- t(tab_snps)
nloci <- length(colnames(loci))
nsamples <- length(rownames(loci))
failed_loci <- which(colSums(is.na(loci))==nrow(loci))
failed_samples <- which(colSums(is.na(tab_snps))==nrow(tab_snps))
####KasperH added: save failed_loci and failed_samples; these are again needed in script 1c.
saveRDS(failed_loci, file = file.path(output_Robjects, "failed_loci.Rds"), version = 2)
saveRDS(failed_samples, file = file.path(output_Robjects, "failed_samples.Rds"), version = 2)
# per locus
seq_per_locus <- vector()
for(i in 1:nloci){
seq_per_locus[i] <- length(which(!(is.na(loci[,i]))))
}
names(seq_per_locus) <- colnames(loci)
seq_per_locus_prop <- seq_per_locus/nsamples
# per sample
seq_per_sample <- vector()
for(i in 1:length(colnames(tab_snps))){
seq_per_sample[i] <- length(which(!(is.na(tab_snps[,i]))))
}
names(seq_per_sample) <- colnames(tab_snps)
seq_per_sample_prop <- seq_per_sample/nloci
# proportion of target sequence length
if(targets_file_format == "AA"){
targets_length_all <- lengths(read.FASTA(fasta_file_with_targets, type = "AA"))*3
} else if(targets_file_format == "DNA"){
targets_length_all <- lengths(read.FASTA(fasta_file_with_targets))
} else {
print("Warning! Target file type not set properly. Should be 'DNA' or 'AA'!")
}
gene_names <- unique(gsub(".*-","",gsub(" .*","",names(targets_length_all))))
max_target_length <- vector()
for(i in 1:length(gene_names)){
max_target_length[i] <- max(targets_length_all[grep(paste("\\b",gene_names[i],"\\b",sep=""),names(targets_length_all))])
}
names(max_target_length) <- gene_names
comb_target_length <- sum(max_target_length)
comb_seq_length_samples <- colSums(tab_length, na.rm = T)
prop_target_length_per_sample <- comb_seq_length_samples/comb_target_length
mean_seq_length_loci <- rowMeans(tab_length, na.rm = T)
names(mean_seq_length_loci) <- gene_names
prop_target_length_per_locus <- mean_seq_length_loci/max_target_length
# application of thresholds
outsamples_missing_loci <- seq_per_sample_prop[which(seq_per_sample_prop < remove_samples_with_less_than_this_propotion_of_loci_recovered)]
outsamples_missing_target <- prop_target_length_per_sample[which(prop_target_length_per_sample < remove_samples_with_less_than_this_propotion_of_target_sequence_length_recovered)]
outsamples_missing <- unique(names(c(outsamples_missing_loci,outsamples_missing_target)))
outloci_missing_samples <- seq_per_locus_prop[which(seq_per_locus_prop < remove_loci_with_less_than_this_propotion_of_samples_recovered)]
outloci_missing_target <- prop_target_length_per_locus[which(prop_target_length_per_locus < remove_loci_with_less_than_this_propotion_of_target_sequence_length_recovered)]
outloci_missing <- unique(names(c(outloci_missing_samples,outloci_missing_target)))
# removing bad loci and samples from the table
tab_snps_cl1 <- tab_snps
if(length(outsamples_missing) != 0){
tab_snps_cl1 <- tab_snps_cl1[,-which(colnames(tab_snps) %in% outsamples_missing)]
}
if(length(outloci_missing) != 0){
tab_snps_cl1 <- tab_snps_cl1[-which(rownames(tab_snps) %in% outloci_missing),]
}
loci_cl1 <- t(tab_snps_cl1)
#Load metadata to relate samples to tribes.
metadata <- read.csv(file = "../2e.metadata.csv", header = T)
#Get overview of samples and tribes still in dataset after step 1: Reducing missing data.
samples_cl1 <- data.frame(sample = colnames(tab_snps_cl1), tribe = metadata$Tribe[match(colnames(tab_snps_cl1), metadata$Library_ID)])
samples_cl1
#Print warning if one or more samples could not be associated with a tribe (in which case the metadata file probably has missing samples or mis-spelled sample names).
if (sum(is.na(samples_cl1$tribe)) > 0) {
print("WARNING: One or more samples in the dataset are not listed in the metadata file!")
print(paste0("Add details for the following samples:"))
sprintf(samples_cl1$sample[which(is.na(samples_cl1$tribe))])
}
#Get an overview of sample sizes by tribe.
samples_cl1_tribe_totals <- data.frame(table(samples_cl1$tribe))
colnames(samples_cl1_tribe_totals) <- c("tribe", "count")
samples_cl1_tribe_totals <- samples_cl1_tribe_totals[order(-samples_cl1_tribe_totals$count),]
samples_cl1_tribe_totals
#Because we need a good sample size before we can make any judgment on outliers, we will focus only on tribes with 2 or more samples.
#Samples placed in bin tribe 'unplaced' will be analyzed together with the smaller tribes.
tribes_cl1_to_analyze <- samples_cl1_tribe_totals$tribe[samples_cl1_tribe_totals$count > 1]
tribes_cl1_to_analyze <- tribes_cl1_to_analyze[-which(tribes_cl1_to_analyze == "unplaced")]
tribes_cl1_to_analyze <- c(as.character(tribes_cl1_to_analyze), "other")
#Create a copy of the snps table that we will use to remove loci from, tribe by tribe, in the loop below.
#(This copy was made only after finding loci to remove when studying all samples at a time in the original script.)
tab_snps_cl2a <- tab_snps_cl1
#Create lists to store details on removed loci in the loop below, by tribe and by sample.
outloci_para_by_tribe <- list()
outloci_para_each_from_tribe <- list()
#Now we can loop through the tribes and repeat the above script to remove outliers by tribe.
for (tribe in tribes_cl1_to_analyze) {
print(tribe)
#Create a vector of samples for this tribe.
if (tribe != "other") {
samples_cl1_tribe <- samples_cl1[samples_cl1$tribe == tribe,1]
} else {
samples_cl1_tribe <- samples_cl1[!samples_cl1$tribe %in% tribes_cl1_to_analyze[tribes_cl1_to_analyze != "other"],1]
}
####KasperH generate tables without zeros to count only loci with SNPs.
tab_snps_cl1_tribe_nozero <- tab_snps_cl1[,colnames(tab_snps_cl1) %in% samples_cl1_tribe]
tab_snps_cl1_tribe_nozero[which(tab_snps_cl1_tribe_nozero==0)] <- NA
#Remove any rows with only NAs which cannot be used further for calculation of colMeans.
tab_snps_cl1_tribe_nozero <- tab_snps_cl1_tribe_nozero[rowSums(is.na(tab_snps_cl1_tribe_nozero))<ncol(tab_snps_cl1_tribe_nozero),]
nsamples_cl1_tribe <- length(colnames(tab_snps_cl1_tribe_nozero))
loci_cl1_tribe<-t(tab_snps_cl1_tribe_nozero)
loci_cl1_colmeans_tribe <- colMeans(as.matrix(loci_cl1_tribe), na.rm = T)
nloci_cl1_tribe <- length(colnames(loci_cl1_tribe))
nsamples_cl1_tribe <- length(colnames(tab_snps_cl1_tribe_nozero))
loci_cl1_colmeans_mean_tribe <- round(mean(loci_cl1_colmeans_tribe),4)
loci_cl1_colmeans_median_tribe <- round(median(loci_cl1_colmeans_tribe),4)
# applying chosen threshold
if (length(remove_loci_for_all_samples_with_more_than_this_mean_proportion_of_SNPs) != 1 || remove_loci_for_all_samples_with_more_than_this_mean_proportion_of_SNPs == "none"){
outloci_para_this_tribe <- vector()
threshold_value_tribe <- 1
} else if (remove_loci_for_all_samples_with_more_than_this_mean_proportion_of_SNPs == "outliers"){
threshold_value_tribe <- 1.5*IQR(loci_cl1_colmeans_tribe, na.rm = TRUE )+quantile(loci_cl1_colmeans_tribe, na.rm = TRUE )[4]
outloci_para_this_tribe <- loci_cl1_colmeans_tribe[which(loci_cl1_colmeans_tribe > threshold_value_tribe)]
outloci_para_this_tribe_names <- names(outloci_para_all_values_tribe)
} else if (remove_loci_for_all_samples_with_more_than_this_mean_proportion_of_SNPs == "file"){
if(file.exists(file_with_putative_paralogs_to_remove_for_all_samples) == FALSE){
print("File with list of paralogs to remove for all samples does not exist.")
} else {
outloci_para_this_tribe <- readLines(file_with_putative_paralogs_to_remove_for_all_samples)
outloci_para_this_tribe_names <-loci_cl1_colmeans_tribe[which(names(loci_cl1_colmeans_tribe) %in% outloci_para_all_tribe)]
}
} else {
threshold_value_tribe <- remove_loci_for_all_samples_with_more_than_this_mean_proportion_of_SNPs
outloci_para_this_tribe <- loci_cl1_colmeans_tribe[which(loci_cl1_colmeans_tribe > threshold_value_tribe)]
outloci_para_this_tribe_names <- names(outloci_para_this_tribe)
}
# removing marked loci from table
if(length(outloci_para_this_tribe_names)!=0) {
#Subset for the samples corresponding to the tribe and the loci to be removed for this tribe.
tab_snps_cl2a[rownames(tab_snps_cl2a) %in% outloci_para_this_tribe_names, colnames(tab_snps_cl2a) %in% samples_cl1_tribe] <- NA
}
#Put the results in a dataframe for plotting in ggplot.
loci_cl1_colmeans_tribe_dataframe<-data.frame(loci_cl1_colmeans_tribe = loci_cl1_colmeans_tribe, Locus_status = "include")
loci_cl1_colmeans_tribe_dataframe$locus <- rownames(loci_cl1_colmeans_tribe_dataframe)
loci_cl1_colmeans_tribe_dataframe$Locus_status[loci_cl1_colmeans_tribe_dataframe$locus %in% outloci_para_this_tribe_names] <- "remove"
loci_cl1_colmeans_tribe_dataframe <- loci_cl1_colmeans_tribe_dataframe[order(loci_cl1_colmeans_tribe_dataframe$loci_cl1_colmeans_tribe),]
loci_cl1_colmeans_tribe_dataframe$locus <- factor(loci_cl1_colmeans_tribe_dataframe$locus, levels = loci_cl1_colmeans_tribe_dataframe$locus)
#Plot a bar graph.
bar_graph_paralogs_by_tribe<-ggplot(data=loci_cl1_colmeans_tribe_dataframe, aes(x=locus, y=loci_cl1_colmeans_tribe, fill = Locus_status))+
geom_bar(stat='identity', colour = NA)+
ggtitle(paste0("Tribe: ", tribe," (n,samples = ", nsamples_cl1_tribe, ")"),
subtitle = paste0("Threshold value = ", round(threshold_value_tribe,3), ", number of outlier loci = ", length(outloci_para_this_tribe_names))) +
scale_fill_manual(values = c("black","red"))+
geom_hline(yintercept=threshold_value_tribe, linetype="dashed", color = "red", size=0.5)+
xlab(paste0("Locus (n=", nloci_cl1_tribe, ")"))+
ylab("Mean % of SNPs per locus for this tribe")+
theme(axis.text.x=element_blank(), axis.ticks.x=element_blank(),
plot.title = element_text(hjust = 0.5), plot.subtitle = element_text(hjust = 0.5, colour = "red"))
#Register removed loci by tribe, plus bar graph plots.
names(outloci_para_by_tribe[tribe]) <- tribe
outloci_para_by_tribe[[tribe]]$threshold_value_tribe <- threshold_value_tribe
outloci_para_by_tribe[[tribe]]$outloci_para_by_tribe <- outloci_para_this_tribe_names
outloci_para_by_tribe[[tribe]]$samples_cl1_tribe <- samples_cl1_tribe
outloci_para_by_tribe[[tribe]]$bar_graph <- bar_graph_paralogs_by_tribe
#List these in our list object by sample for removal of loci in R script 1c.
for (j in 1:length(samples_cl1_tribe)){
outloci_para_each_from_tribe<-append(outloci_para_each_from_tribe, list(outloci_para_this_tribe_names))
names(outloci_para_each_from_tribe)[length(outloci_para_each_from_tribe)]<-samples_cl1_tribe[j]
}
#outloci_para_each_from_tribe <- sapply(samples_cl1_tribe,function(x) NULL)
#outloci_para_each_from_tribe <- lapply(outloci_para_each_from_tribe[names(outloci_para_each_from_tribe) %in% samples_cl1_tribe], function(x) outloci_para_this_tribe_names)
}
outloci_para_each_from_tribe
config_file <- "./config_inclusive.txt"
# load config
#if (!(exists("config_file"))) {config_file <- "./config.txt"}
source(config_file)
setwd("/Volumes/GoogleDrive/My Drive/Postdoc Naturalis:Osnabrück/Analysis bioinformatics/2021-08-09_Map_for_genus_level_phylogeny_on_Stampede2/results_HybPhaser_allGenes")
config_file
# load config
#if (!(exists("config_file"))) {config_file <- "./config.txt"}
source(config_file)
# load packages
library(ape)
library(ggplot2)
# generate folders
if(name_for_dataset_optimization_subset != ""){
folder_subset_add <- paste("_",name_for_dataset_optimization_subset, sep="")
}else {
folder_subset_add <- ""
}
output_Robjects <- file.path(path_to_output_folder,"00_R_objects", name_for_dataset_optimization_subset)
output_assess <- file.path(path_to_output_folder,paste("02_assessment", folder_subset_add, sep=""))
# check if SNPs count for subset has been done, if not use SNPs count of first run subset with name "")
if(file.exists(file=file.path(output_Robjects,"Table_SNPs.Rds"))){
tab_snps <- readRDS(file=file.path(output_Robjects,"Table_SNPs.Rds"))
tab_length <- readRDS(file=file.path(output_Robjects,"Table_consensus_length.Rds"))
} else {
tab_snps <- readRDS(file=file.path(path_to_output_folder,"00_R_objects/Table_SNPs.Rds"))
tab_length <- readRDS(file=file.path(path_to_output_folder,"00_R_objects/Table_consensus_length.Rds"))
}
tab_snps <- as.matrix(tab_snps)
loci <- t(tab_snps)
loci
length(loci)
View(tab_snps)
